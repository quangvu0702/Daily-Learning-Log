{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from keys import openai_key\n",
    "\n",
    "# Function to use OpenAI autocomplete\n",
    "def generate_autocomplete(question, temperature=0, top_p=1, n=1, system_prompt=\"You are a helpful assistant.\"):\n",
    "    \"\"\"\n",
    "    Generates an autocomplete response using OpenAI's GPT model.\n",
    "    \n",
    "    Parameters:\n",
    "        prompt_text (str): The initial text to complete.\n",
    "        max_tokens (int): The Max number of tokens to generate in the completion.\n",
    "        temperature (float): Controls the creativity (0.0 = deterministic, higher = more creative).\n",
    "        top_p (float): Controls the probability threshold for vocabulary sampling.\n",
    "        n (int): Number of completions to generate.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated completion text.\n",
    "    \"\"\"\n",
    "    # Make sure to set your OpenAI API key here\n",
    "    client = OpenAI(\n",
    "        # This is the default and can be omitted\n",
    "        api_key=openai_key,\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        # Use the ChatCompletion API (chat-based interface)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # Extract and return the generated text from the response\n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the capital of France?\"\n",
    "result = generate_autocomplete(question)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = \"\"\"You are an intelligent SQL assistant. Your job is to generate SQL queries based on the provided database schema.\n",
    "\n",
    "# Rules:\n",
    "# 1. Always respond with the SQL query inside a JSON object using the format: `{\"query\": \"---query---\"}`.\n",
    "# 2. Ensure the query is based strictly on the tables and data provided in the schema.\n",
    "# 3. If a query requests information not available in the tables, return `{\"query\": \"\"}` (an empty query).\n",
    "# 4. The SQL query must be syntactically correct and optimized for performance.\n",
    "# 5. Avoid making assumptions about the data beyond what is provided in the schema.\n",
    "# 6. Do not include any comments or explanations in the response—just the JSON object with the query.\n",
    "\n",
    "# You are a precise SQL assistant that only returns SQL queries formatted in JSON.\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "task = \"\"\"You are an intelligent SQL assistant. Your job is to generate SQL queries based on the provided database schema.\n",
    "\n",
    "Rules:\n",
    "1. Always respond with the SQL query only, without any additional explanation.\n",
    "2. Ensure the query is based strictly on the tables and data provided in the schema.\n",
    "3. If a query requests information not available in the tables, return an empty response.\n",
    "4. The SQL query must be syntactically correct and optimized for performance.\n",
    "5. Avoid making assumptions about the data beyond what is provided in the schema.\n",
    "6. Do not include any comments or explanations in the response—just the SQL query.\n",
    "\n",
    "You are a precise SQL assistant that only returns valid SQL queries.\"\"\"\n",
    "\n",
    "# read schema from file tables.txt\n",
    "with open(\"tables.txt\", \"r\") as f:\n",
    "    schema = f.read()\n",
    "\n",
    "# read examples from file examples.txt\n",
    "with open(\"examples.txt\", \"r\") as f:\n",
    "    examples = f.read()\n",
    "\n",
    "# Combine the task description, schema, and examples\n",
    "system_prompt = task + schema + examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT \n",
      "    campaign.id AS campaign_id, \n",
      "    campaign.name AS campaign_name, \n",
      "    adset.start_date, \n",
      "    adset.end_date, \n",
      "    adset.status\n",
      "FROM \n",
      "    sponsor_adset AS adset\n",
      "INNER JOIN \n",
      "    sponsor_campaign AS campaign \n",
      "ON \n",
      "    adset.campaign_id = campaign.id\n",
      "WHERE \n",
      "    adset.status = 'DELIVERING';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "question = \"get all running campaign?\"\n",
    "result = generate_autocomplete(question, system_prompt=system_prompt)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samwell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
